# Лекция №8

## Анализ текстов

### Термины 

- NLP - обработка текстов;
- NLU - понимание текстов;
- NLG - генерация текстов.

Задачи с текстами:
- Классификация(тональность, настроение, автор);
- Перевод текстов(текст -> текст);
- Описание _нетекстов_(изображения и тд);
- Генерация объектов из текста.

- токен - элемент последовательности(слово, несколько букв);
- словарь - допустимые токены.

### Свертки в текстах

- каждый токен записываем в виде вектора;
- как работать с произвольной __n-граммой__:
  - специальный pooling;

Пример:
- токены представляем векторами, получаем матрицу - описание текста;
- свертка + пулинг получают вектор - признаки в тексте;
- далее полносвязный элемент для задачи.

### seq2seq

- Лучше точность, если перевернуть предложение(последнее слово будет первым и тд);
- Недостаток: __смысл предожения кодируется вектором фиксированной длины__;

### attention

- сеть подглядывает в данные(исходное предложение, чтобы понять контекст);
- добавляем контекстные веса и считаем каждый раз связь состояния кодировщика с токеном:
  - скалярное произведение;
  - нелинейные преобразования;
  - косинусное расстояние.
- для каждого токена образуются контекстные веса $\alpha_i$:
  - из визуализации весов можно судить о связи слов в текстах.
- случился огонь... 
