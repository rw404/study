{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция №6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме продвижения _вглубь_ сети образуются межэлементные связи на одном слое.\n",
    "\n",
    "### Обучение\n",
    "\n",
    "- Граф связей(расписанная модель с раскрытыми связями) обучаем, как и обычную сеть;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN-модуль\n",
    "\n",
    "- Конкатенируем вход с предыдущим результатом и внутренней функцией активации `tanh`.\n",
    "\n",
    "__Проблема__:\n",
    "- Забывчивость(исправляют LSTM):\n",
    "  - _residual_ блоки для сохранения сигналов;\n",
    "  - первое слагаемое - совокупность входа и предыдущего состояния(forget gate);\n",
    "  - Используем состояние и вход для определения текущего состояния(input gate);\n",
    "  - Результат ячейки - совокупность input gate и forget gate(cell update)\n",
    "  - выходной gate - формирует результат и состояние, учитывая вход и предыдущее состояние.\n",
    "\n",
    "GRU схожи с LSTM, но исключают второй параметр выхода ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1376, -0.0534,  0.0858]]]) [tensor([[[-0.1376, -0.0534,  0.0858]]]), tensor([[[-0.5819, -0.1293,  0.1176]]])]\n",
      "tensor([[[-0.2166,  0.2641,  0.1926]]]) [tensor([[[-0.2166,  0.2641,  0.1926]]]), tensor([[[-0.5162,  0.4397,  0.4905]]])]\n",
      "tensor([[[-0.0089,  0.0961,  0.0392]]]) [tensor([[[-0.0089,  0.0961,  0.0392]]]), tensor([[[-0.0238,  0.1715,  0.1055]]])]\n",
      "tensor([[[0.0523, 0.0938, 0.0164]]]) [tensor([[[0.0523, 0.0938, 0.0164]]]), tensor([[[0.1161, 0.1477, 0.0610]]])]\n",
      "tensor([[[-0.1366,  0.1296, -0.0530]]]) [tensor([[[-0.1366,  0.1296, -0.0530]]]), tensor([[[-0.6740,  0.3636, -0.0680]]])]\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=3, hidden_size=3, num_layers=1, \n",
    "bias=True, batch_first=False, dropout=0, bidirectional=False) \n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3)) \n",
    "inputs = [torch.randn(1, 3) for _ in range(5)] \n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print(out.data, [h.data for h in hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6211, -2.6352,  1.1328]],\n",
      "\n",
      "        [[ 2.4052,  0.5578,  1.6831]],\n",
      "\n",
      "        [[-0.3897, -1.0508, -0.5149]],\n",
      "\n",
      "        [[-0.1309,  0.2160, -0.0988]],\n",
      "\n",
      "        [[ 0.6567, -2.1673,  2.0208]]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0483, -0.1339, -0.1824]],\n",
      "\n",
      "        [[-0.0020,  0.2097,  0.0826]],\n",
      "\n",
      "        [[ 0.0455,  0.0950, -0.0318]],\n",
      "\n",
      "        [[ 0.0810,  0.1086, -0.0248]],\n",
      "\n",
      "        [[-0.1339,  0.1334, -0.0901]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.1339,  0.1334, -0.0901]]], grad_fn=<StackBackward0>), tensor([[[-0.6609,  0.3774, -0.1158]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        hidden = [400, 300, 200, 100]\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden[0],\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            2 * hidden[0]\n",
    "            , hidden[1],\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(2 * hidden[1], hidden[2],\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        self.fc1 = nn.Linear(2 * hidden[3], 50)\n",
    "        self.selu = nn.SELU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self._reinitialize()\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.fc2(self.selu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teacher forcing:\n",
    "  - подаем каждый раз истинную метку:\n",
    "    - Быстрее обучается;\n",
    "    - Отличается на тестировании.\n",
    "- Professor forcing:\n",
    "  - стараемся делать элементы похожими;\n",
    "- Scheduled sampling:\n",
    "  - смешиваем значение выборки с генерированным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "    encoder_optimizer, decoder_optimizer, criterion, max_length=15):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) \n",
    "    loss = 0\n",
    "    decoder_input = torch.tensor([[\"a\"]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_teacher_forcing:\n",
    "    # Teacher forcing: Feed the target as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden,\n",
    "        encoder_outputs)\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "else:\n",
    "# Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden,\n",
    "        encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach() # detach from history as input\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "    if decoder_input.item() == EOS_token:\n",
    "        break\n",
    "\n",
    "loss.backward()\n",
    "return loss.item() / target_length\n",
    "decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN глубины не больше 4(обычно)\n",
    "\n",
    "Для обучения(чтобы побороть gradient vanishing):\n",
    "- ограничение шагов обратного распространения;\n",
    "- оптимизация с гессианом\n",
    "- специальная регуляризация\n",
    "\n",
    "### Эхо-сети\n",
    "\n",
    "- берем случайные паттерны(связи модудлей), а обучаем все модули кром полученных паттернов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# обучающая выборка\n",
    "training_data = [(\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "                 (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])]\n",
    "# соответствие класс-id\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "# построить соответствие токен-id\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6 # надо делать существенно больше!\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # embeddings + hidden states -> hidden states\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # linear layer hidden state -> tag\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = torch.nn.functional.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0274, -1.3471, -0.9621],\n",
      "        [-0.9032, -1.3646, -1.0811],\n",
      "        [-0.9205, -1.3213, -1.0940],\n",
      "        [-0.8779, -1.3206, -1.1477],\n",
      "        [-0.8887, -1.3120, -1.1409]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], \n",
    "    word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    for sentence, tags in training_data:\n",
    "        model.zero_grad()\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        tag_scores = model(sentence_in)\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[-1.0498, -1.2391, -1.0207],\n",
      "        [-0.9311, -1.2415, -1.1491],\n",
      "        [-0.9565, -1.2035, -1.1532],\n",
      "        [-0.9014, -1.2005, -1.2278],\n",
      "        [-0.9188, -1.1974, -1.2073]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], \n",
    "    word_to_ix)\n",
    "    print(inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
