{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9cab65-7beb-430a-96d7-e2081c45a15b",
   "metadata": {},
   "source": [
    "# Лекция №4 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752ba1c2-ea24-4d14-9aad-6f6e37101466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2e5fc-9338-4e1b-b9bc-33474ef395c3",
   "metadata": {},
   "source": [
    "## Полносвязная классификация\n",
    "\n",
    "- Используем изображение для представления в виде одномерного вектора;\n",
    "- домножаем на специальный вектор весов;\n",
    "- прибавляем смещение и полчаем вектор вероятностей классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbbe90b-2bc2-4fd9-9ba8-55f414c5f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlinear(nn.Module):\n",
    "    def __init__(self, input_size, ouput_size):\n",
    "        super(Mlinear, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=28)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 10)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf99e7-f639-43a2-96af-40ad1b05847b",
   "metadata": {},
   "source": [
    "__Проблемы сети:__\n",
    "- простая модель;\n",
    "- объекты расположены в одном месте кадра;\n",
    "- много параметров для простой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc648d7-99f0-4819-8dee-fa5d6521bd27",
   "metadata": {},
   "source": [
    "### Сверточные нейронные сети(ConvNet, CNN)\n",
    "\n",
    "- оперируем не пикселями, а объектами(реализация механизма свертки):\n",
    "    $(I\\times K)_{xy}=\\sum_{i=1}^h\\sum_{j=1}^rK_{ij}I_{x+i-1, y+j-1}$\n",
    "- свертка извлекает паттерны объекта вместо свзяей пикселей;\n",
    "- свертку можно понимать, как __фильтр__ - специальная матрица $I$ из п.1, которая применяет задаваемый эффект к изображению(размытие, Собель и тд), __НО__\n",
    "- в cnn фильтры обучаемые, т.е. специально выделять границы не будут, будут учиться __извлекать искомые паттерны__;\n",
    "- важное отличие от полносвязных - __чем больше слоев, тем лучше описание объекта__, т.е. больше сверток - лучше, с полносвязными не так.\n",
    "\n",
    "Характеристики сверток:\n",
    "- число входных(выходных) каналов;\n",
    "- шаг свертки;\n",
    "- отступ;\n",
    "- размер ядра.\n",
    "\n",
    "__Когда добавляется свертка, то увеличивается число каналов карты отклика__.\n",
    "\n",
    "`dilation` - зазор _между пикселями в одном фильтре_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd66c35-3314-4154-a5ee-7b2b69f82381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 26, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(20, 16, 50, 100)\n",
    "m = nn.Conv2d(16, 32, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3ca11-4bd8-49da-85c4-81111610e7a2",
   "metadata": {},
   "source": [
    "### Линейная операция\n",
    "\n",
    "- Свертка реализует линейное преобразование, поэтому для работы свертки нужно быстро умножать матрицы(используя параллелизм, ускоряем процесс обучения - __CUDA__)\n",
    "\n",
    "#### Одноканальная свертка\n",
    "\n",
    "- помогает менять число каналов, сохраняя пространственную информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfdb02-aded-45e8-91b9-427c0d16a303",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "- Свертки показыают отклик на признаки в каждом сегменте кадра - __нужно находить объект инвариантно от смещений__\n",
    "- Для этого реализуют __пулинг__ - преобразование, инвариантное к сдвигам в рамках локальной области.\n",
    "\n",
    "Параметр `ceil_mode` - как вычислять размер результата, когда на заданные кадры изображение не делится.\n",
    "\n",
    "__Backprop__:\n",
    "1. Когда вычисляем max-pool, запоминаем позиции максимумов;\n",
    "2. В ходе обратного распространения заполняем все нулями кроме позиций, где был изначально максимум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae69683-1b58-45bd-8a62-a5b8ea68f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 24, 31])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(20, 16, 50, 32)\n",
    "\n",
    "m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
    "\n",
    "print(m(input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420aa07f-24e9-452b-9349-17df3ebdbcdd",
   "metadata": {},
   "source": [
    "### Строение сети CNN\n",
    "\n",
    "__[Conv, NonLinear, Pool] $\\times$ k__:\n",
    "- построили карту отклика для фильтров на всем изображении;\n",
    "- сохранили релевантные значения из всех откликов;\n",
    "- использовали пулинг для сокращения размерности и сохранения инвариантности алгоритма.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3263219-a4e8-450e-a773-8f31227cf2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 1, 26, 26])\n",
      "torch.Size([1, 1, 13, 13])\n",
      "torch.Size([1, 1, 11, 11])\n",
      "torch.Size([1, 1, 6, 6])\n",
      "ceil_mode=True\n",
      "OR\n",
      "torch.Size([1, 1, 5, 5])\n",
      "ceil_mode=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "f = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "print(x.shape)\n",
    "x = f(x)\n",
    "print(x.shape)\n",
    "x = F.max_pool2d(x, kernel_size=2)\n",
    "print(x.shape)\n",
    "x = f(x)\n",
    "print(x.shape)\n",
    "x1 = F.max_pool2d(x, kernel_size=2, ceil_mode=True)\n",
    "print(x1.shape)\n",
    "print(\"ceil_mode=True\\nOR\")\n",
    "x2 = F.max_pool2d(x, kernel_size=2)\n",
    "print(x2.shape)\n",
    "print(\"ceil_mode=False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29f3de-e7c1-4494-a754-3b2cb611ae87",
   "metadata": {},
   "source": [
    "## Flatten\n",
    "\n",
    "После применения CNN остается уменьшенная карта признаков, но для работы полносвязного модуля нужно представить эту карту как вектор, для этого:\n",
    "- можно _вытянуть_ отклики в один вектор;\n",
    "- GAP - сохранение ключевой информации с каждого слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c4702-d1ac-47fa-88e9-9131af3caffb",
   "metadata": {},
   "source": [
    "## Архитектуры CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd473412-cc9b-4275-8029-a7b2cd2aa5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(sel, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 120, 5, stride=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, n_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab34eb-147f-473a-b386-f9bade489cdb",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "- Использует два параллельных пути(использовалось, чтобы задействовать одновременно две GPU)\n",
    "- Используется ReLU, Dropout, Augmentations\n",
    "\n",
    "> Ключевая сложность сети все равно хранится в голове, т.к. из __обширного итогового признакового проастранства__ нужно получить __значительно меньшее число значений__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6f860-9afe-4da3-ac1b-d3647208c384",
   "metadata": {},
   "source": [
    "### VGG\n",
    "\n",
    "- Все свертки __$3\\times3$__:\n",
    "    - двукратное применение простых сверток эквивалентно одинарному применению усложненной;\n",
    "- Очень много параметров $\\sim130M$;\n",
    "- Более глубокая сеть;\n",
    "- Обучали более простую сеть, затем полученными весами инициализировали более сложную сеть и дообучали уже ее;\n",
    "- Сжимает размеры карты, увеличивает количество каналов вдвое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a52381ab-03c2-4a06-96b4-83d632e19345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=1000):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        self.features=features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(), \n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(), \n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    \n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg11(**kwargs):\n",
    "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73c87a26-0e01-4b2f-ba8a-518015d6a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg11()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f97a6c-d72d-4402-8865-6b388faf8105",
   "metadata": {},
   "source": [
    "### GoogleNet\n",
    "\n",
    "- 3 выхода(тройная ошибка и возможность избежать затухания градиентов);\n",
    "- используются GAP, поэтому отказ от полносвязных слоев.\n",
    "\n",
    "#### Inception\n",
    "\n",
    "- Вход распределяется на 4 параллельных пути:\n",
    "    - $1\\times1$ свертки;\n",
    "    - $3\\times3$ свертки;\n",
    "    - $5\\times5$ свертки;\n",
    "    - $3\\times3$ max-pooling;\n",
    "    - __Проблема в итоговом числе каналов, поэтому добавляются одноканальные свертки__\n",
    "- В 3-ей версии Inception идея факторизации сверток(Линал - ранг произведения не превосходит ранга множителей, поэтому ранг свертки должен быть 1, ранг 0 - нулевая матрица):\n",
    "    - Тогда вместо свертки с матрицей можно две свертки с векторами(упрощение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d4ad23-a3ab-455c-a4bd-d65648a596cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_base(nn.Module):\n",
    "    def __init__(self, depth_dim, input_size, config):\n",
    "        super(Inception_base, self).__init__()\n",
    "        self.depth_dim = depth_dim\n",
    "        # 1x1\n",
    "        self.conv1 = nn.Conv2d(input_size, out_channels=config[0][0], kernel_size=1, stride=1, padding=0)\n",
    "        # 3x3_bottleneck + 3x3\n",
    "        self.conv3_1 = nn.Conv2d(input_size, out_channels=config[1][0], kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3_3 = nn.Conv2d(config[1][0], config[1][1], kernel_size=3, stride=1, padding=1)\n",
    "        # 5x5_bottleneck + 5x5\n",
    "        self.conv5_1 = nn.Conv2d(input_size, out_channels=config[2][0], kernel_size=1, stride=1, padding=0)\n",
    "        self.conv5_5 = nn.Conv2d(config[2][0], config[2][1], kernel_size=5, stride=1, padding=2)\n",
    "        # maxpool + 1x1\n",
    "        self.max_pool_1 = nn.MaxPool2d(kernel_size=config[3][0], stride=1, padding=1)\n",
    "        self.conv_max_1 = nn.Conv2d(input_size, out_channels=config[3][1], kernel_size=1, stride=1,\n",
    "        padding=0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output1 = F.relu(self.conv1(input))\n",
    "        output2 = F.relu(self.conv3_1(input))\n",
    "        output2 = F.relu(self.conv3_3(output2))\n",
    "        output3 = F.relu(self.conv5_1(input))\n",
    "        output3 = F.relu(self.conv5_5(output3))\n",
    "        output4 = F.relu(self.conv_max_1(self.max_pool_1(input)))\n",
    "        return torch.cat([output1, output2, output3, output4], dim=self.depth_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429c8e4-4f1a-4596-a841-d9eeeb65ecbe",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "- Кроме применения сети добавляется еще исходное значение на каждом применении свертки:\n",
    "    - Научиться переводить преобразование в 0 проще, чем научить тождественному отображению;\n",
    "    - Сумма в обратном распространении помогает избавиться от затухания градиентов.\n",
    "- 152 слоя(в разы больше предшественников);\n",
    "- GAP;\n",
    "- BatchNorm;\n",
    "- SGD+Momentum;\n",
    "- Убрали Dropout.\n",
    "\n",
    "> Прокидование в слое помогло уменьшить ошибку в более глубоких сетях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7cb07f-9525-43b7-914d-40cfdfe4f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): # building block ResNet 34 - не bottleneck\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a770e30-4126-4512-be67-d9cc44f87a22",
   "metadata": {},
   "source": [
    "### SENet\n",
    "\n",
    "- В результате работы получает еще вектор важности каждого канала, затем его применяет к полученным каналам;\n",
    "- Помогает уменьшить ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7542e116-9a02-4880-8f35-d04e5dde17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), \n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(channel // reduction, channel, bias=False),\n",
    "                                nn.Sigmoid()\n",
    "                               )\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e43a6-39d6-459c-a812-38c65a8271f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
