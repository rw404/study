# Лекция №3

# Синхронизация процессов

## Данные для тестирования

Для проверки и сравнения работоспособности программ будет использоваться следующий фрагмент для
генерации данных на языке C++:

```c++
template <size_t rows, size_t cols>
void
init(float (&A)[rows][cols])
{
  for (int i=0; i < rows; ++i) {
    for (int j=0; j < cols; ++j) {
      A[i][j] = (i*j)*(i+j);
    }
  }
}
```

То есть данные имеют следующий вид:
```bash
Init:
0 0 0 0 0 0 0 0 0 0 
0 2 6 12 20 30 42 56 72 90 
0 6 16 30 48 70 96 126 160 198 
0 12 30 54 84 120 162 210 264 324 
0 20 48 84 128 180 240 308 384 468 
0 30 70 120 180 250 330 420 520 630 
0 42 96 162 240 330 432 546 672 810 
0 56 126 210 308 420 546 686 840 1008 
0 72 160 264 384 520 672 840 1024 1224 
0 90 198 324 468 630 810 1008 1224 1458 
```

## Механизм событий

SOR.cpp[Последовательная реализация]:
```c++
#include <iostream>
#include <omp.h>

...

int
main()
{
  size_t size = 10;
  float A[10][10];
  
  init(A); // Инициаллизируем массив описанными данными 
  std::cout << "Init:\n";
  out(A);  // Вывод данных

  double start = omp_get_wtime(); // Запуск времени до начала алгоритма
  for (int i = 1; i < size-1; ++i) {
    for (int j = 1; j < size-1; ++j) {
      A[i][j] = (A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
    }
  }
  double end = omp_get_wtime(); // Конец работы алгоритма

  std::cout << std::endl << "Output:\n";
  out(A);  // Вывод данных после изменений
  std::cout << "Time: " << end-start << std::endl;
  return 0;
}
```

Результат:
```bash
Init:
0 0 0 0 0 0 0 0 0 0 
0 2 6 12 20 30 42 56 72 90 
0 6 16 30 48 70 96 126 160 198 
0 12 30 54 84 120 162 210 264 324 
0 20 48 84 128 180 240 308 384 468 
0 30 70 120 180 250 330 420 520 630 
0 42 96 162 240 330 432 546 672 810 
0 56 126 210 308 420 546 686 840 1008 
0 72 160 264 384 520 672 840 1024 1224 
0 90 198 324 468 630 810 1008 1224 1458 

Output:
0 0 0 0 0 0 0 0 0 0 
0 3 7.75 14.4375 23.1094 33.7773 46.4443 61.1111 77.7778 90 
0 7.75 18.875 33.8281 52.7344 75.6279 102.518 133.407 168.296 198 
0 14.4375 33.8281 58.9141 89.9121 126.885 169.851 218.815 273.778 324 
0 23.1094 52.7344 89.9121 134.956 187.96 248.953 317.942 394.93 468 
0 33.7773 75.6279 126.885 187.96 258.98 339.983 430.981 531.978 630 
0 46.4443 102.518 169.851 248.953 339.983 442.992 557.993 684.993 810 
0 61.1111 133.407 218.815 317.942 430.981 557.993 698.997 853.997 1008 
0 77.7778 168.296 273.778 394.93 531.978 684.993 853.997 1039 1224 
0 90 198 324 468 630 810 1008 1224 1458 
Time: 1.19209e-06
```

Параллелизм:
- Распарарллеливаем вычисления, деля матрицу на __отделимые столбцы__(например, 1-3 столбцы у 1-ой нити,
  4-6 у 2-ой и тд);

Реализация этого парарллелизма:
```c++

#include <iostream>
#include <omp.h>

...

int
main()
{
  size_t size=10;
  float A[10][10];
  int iam, numt, limit;
  int isync[16];

  init(A);
  std:: cout << "Init:\n";
  out(A);

  double start = omp_get_wtime();
  #pragma omp parallel private(iam, numt, limit)
  {
    iam=omp_get_thread_num();
    numt=omp_get_num_threads();
    limit=std::min(numt-1, (int)size-3);
    isync[iam]=0;
    
    #pragma omp barrier
    for (int i=1; i<size-1; ++i) {
      if ((iam>0) && (iam <= limit)) {
        for (; isync[iam-1]==0;);
        isync[iam-1]=0;
      } 
      #pragma omp for schedule(static) nowait
      for (int j=1; j<size-1; ++j) {
        A[i][j] = (A[i-1][j] + A[i][j-1] + A[i+1][j] + A[i][j+1])/4;
      }
      if (iam < limit) {
        for (;isync[iam]==1;);
        isync[iam]=1;
      }
    }
  }
  double end = omp_get_wtime();
  std::cout << std::endl << "Output:\n";
  out(A);

  std::cout << "Time: " << end-start << std::endl;
  return 0;
}
```

Результат:
```bash
Init:
0 0 0 0 0 0 0 0 0 0 
0 2 6 12 20 30 42 56 72 90 
0 6 16 30 48 70 96 126 160 198 
0 12 30 54 84 120 162 210 264 324 
0 20 48 84 128 180 240 308 384 468 
0 30 70 120 180 250 330 420 520 630 
0 42 96 162 240 330 432 546 672 810 
0 56 126 210 308 420 546 686 840 1008 
0 72 160 264 384 520 672 840 1024 1224 
0 90 198 324 468 630 810 1008 1224 1458 

Output:
0 0 0 0 0 0 0 0 0 0 
0 3 7.75 14.4375 23.1094 33.7773 46.4443 61.1111 77.7778 90 
0 7.75 18.875 33.8281 52.7344 75.6279 102.518 133.407 168.296 198 
0 14.4375 33.8281 58.9141 89.9121 126.885 169.851 218.815 273.778 324 
0 23.1094 52.7344 89.9121 134.956 187.96 248.953 317.942 394.93 468 
0 33.7773 75.6279 126.885 187.96 258.98 339.983 430.981 531.978 630 
0 46.4443 102.518 169.851 248.953 339.983 442.992 557.993 684.993 810 
0 61.1111 133.407 218.815 317.942 430.981 557.993 698.997 853.997 1008 
0 77.7778 168.296 273.778 394.93 531.978 684.993 853.997 1039 1224 
0 90 198 324 468 630 810 1008 1224 1458 
Time: 0.000467062
```

## Модель памяти в OpenMP

Общая память `int i=0;`, есть __2 нити__:
- Нить 0: `i++` (при входе 0 получаем `i=1`);
- Нить 1: Хочет получить последнее изменение и увеличить `i` на 2.

Для этого используется `omp flush(i)` для возвращения актуального значения из `i` из текущей нити.

__В новых версиях openMp__ есть модификации `flush` для уведомления других нитей об изменениях.

Другая версия парарллелизма:
```c++
...

int
main()
{
  ...
  
  #pragma omp parallel
  {
    int iam=omp_get_thread_num();
    int numt = omp_get_num_threads();
    for (int newi=1; newi < size-1+numt-1; newi++) {
      int i=newi-iam;
      #pragma omp for
      for (int j=1; j<size-1; j++) {
        if ((i >=1) && (i<size-1)) {
          A[i][j] = (A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
        }
      }
    }
  }
  
  ...  

}
```

Результат:
```bash

Init:
0 0 0 0 0 0 0 0 0 0 
0 2 6 12 20 30 42 56 72 90 
0 6 16 30 48 70 96 126 160 198 
0 12 30 54 84 120 162 210 264 324 
0 20 48 84 128 180 240 308 384 468 
0 30 70 120 180 250 330 420 520 630 
0 42 96 162 240 330 432 546 672 810 
0 56 126 210 308 420 546 686 840 1008 
0 72 160 264 384 520 672 840 1024 1224 
0 90 198 324 468 630 810 1008 1224 1458 

Output:
0 0 0 0 0 0 0 0 0 0 
0 3 7.75 14.4375 23.1094 33.7773 46.4443 61.1111 77.7778 90 
0 7.75 18.875 33.8281 52.7344 75.6279 102.518 133.407 168.296 198 
0 14.4375 33.8281 58.9141 89.9121 126.885 169.851 218.815 273.778 324 
0 23.1094 52.7344 89.9121 134.956 187.96 248.953 317.942 394.93 468 
0 33.7773 75.6279 126.885 187.96 258.98 339.983 430.981 531.978 630 
0 46.4443 102.518 169.851 248.953 339.983 442.992 557.993 684.993 810 
0 61.1111 133.407 218.815 317.942 430.981 557.993 698.997 853.997 1008 
0 77.7778 168.296 273.778 394.93 531.978 684.993 853.997 1039 1224 
0 90 198 324 468 630 810 1008 1224 1458 
Time: 0.000458956
```

Проблемы этого решения:
- отсутствие `nowait` влечет добавление барьерных синхронизаций;
- работает на барьерной синхронизации по завершении цикла по `j`;

Графическая идея -- __ступенчатое распределение по нитям__(ступенька, растущая вправо вверх)

__Хуже предыдущего__, т.к. ждем все нити, а не только последнего.

## Ordered

Добавление прагмы `ordered` позволяет добиться параллелизма, в котором выполнение будет
производиться как в последовательной версии:

```c++
#include <iostream>
#include <omp.h>

...

int
main()
{
  ...
  
  #pragma omp parallel for ordered(2) shared(A) 
  // Разделяем нити на 2 последующих цикла
  for (int i=1; i<size-1; ++i) {
    for (int j=1; j<size-1; ++j) {
#pragma omp ordered depend(sink: i-1, j) depend(sink:i, j-1)
      // Ждем события, что будут посчитаны описанные витки
      A[i][j] = (A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
#pragma omp ordered depend(source)
      // Информируем, что нити закончили работу с этой областью
    }
  }
  
  ...
}
```

Результат:
```bash
Output:
0 0 0 0 0 0 0 0 0 0 
0 3 7.75 14.4375 23.1094 33.7773 46.4443 61.1111 77.7778 90 
0 7.75 18.875 33.8281 52.7344 75.6279 102.518 133.407 168.296 198 
0 14.4375 33.8281 58.9141 89.9121 126.885 169.851 218.815 273.778 324 
0 23.1094 52.7344 89.9121 134.956 187.96 248.953 317.942 394.93 468 
0 33.7773 75.6279 126.885 187.96 258.98 339.983 430.981 531.978 630 
0 46.4443 102.518 169.851 248.953 339.983 442.992 557.993 684.993 810 
0 61.1111 133.407 218.815 317.942 430.981 557.993 698.997 853.997 1008 
0 77.7778 168.296 273.778 394.93 531.978 684.993 853.997 1039 1224 
0 90 198 324 468 630 810 1008 1224 1458 
Time: 0.000658035
```

# Механизм событий и семафоров

- Есть переменная `s`, которая показывает, что в системе произошли события
- Есть следующие операторы:
  - POST -- __разблокирует ожидающие события__, например события `s`;
  - WAIT -- __ожидание события__;
  - CLEAR -- __очистка события(прсивоить 0)__

Реализация параллелизма на основе событий:
```c++

#include <iostream>


int
main()
{
  float A[5][5];
  struct event s[5][5]; //События

  for (i=0; i<5; ++i) {
    for (j=0; j<5; ++j) {
      clear(s[i][j]);
    }
  }
  for (j=0; j<5; ++j) {
    post(s[0][j]);
  }

  parfor(i=1; i< 5-1; ++i) {// Ветки цикла могут выполняться разными нитями
    for (j=1; j<5-1; ++j) {
      wait(s[i-1][j]);
      A[i][j] = (A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
      post(s[i][j]);
    } 
  }

  return 0;
}
```

- Рапсределяем работу __вдоль строк по нитям__(1-ая строка -- 1-ая нить);
- Заполняем первую строку матрицами положительными событиями;
- Каждый раз смотрим на состояние нужных сегментов. В случае положительного события обновляем
  текущее состояние;

__Заменяя события на семафоры__, получаем версию программы на основе семафоров.

- WAIT -> P;
- POST -> V.

Если разделяем цикл по нитями не только вдоль строк, но и вдоль столбцов 
`parfor(j=1; j<5-1; ++j)`, то добавляем ожидание событие не только предыдущей строки, но и столбца:
```c++
...

  parfor(i=1; i< 5-1; ++i) {// Ветки цикла могут выполняться разными нитями
    parfor(j = 1; j< 5-1; ++j) {
      wait(s[i-1][j]);
      wait(s[i][j-1]);
      A[i][j] = (A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
      post(s[i][j]);
    } 
  }
  
...
```

## Взаимодействие сообщениями

- __Цель__: избежать гонки процессов за память.

- `send(dest, &msg, msgsize)`
- `receive([src], &msg, msgsize)`

Семафорный аналог `send/receive`:
```c++

#include <iostream>

producer()
{
  int item;
  while(true) {
    produce_item(&item);
    P(empty);
    P(mutex);
    enter_item(item);
    V(mutex);
    V(full);
  }
}

consumer()
{
  int item;
  while(true)
    P(full);
    P(mutex);
    remove_item(&item);
    V(mutex);
    V(empty);
    consume_item(&item);
}
```

Альтернатива на сообщениях -- замена __семафоров на send, receive__:
- `P -> receive, S -> send`.

__Итог__: большинство механизмов взаимореализуемы(семафоры через сообщения, нити через семафоры,
сообщения и тд).
